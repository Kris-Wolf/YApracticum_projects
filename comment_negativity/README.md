# Разметка токсичных комментариев
## Описание проекта
Обучить модель классифицировать комментарии на позитивные и негативные.
## Навыки и инструменты
- imblearn.pipeline.**Pipeline**
- matplotlib.pyplot
- nltk
  - nltk.corpus.**stopwords**
  - nltk.corpus.**wordnet**
  - nltk.**pos_tag**
  - nltk.stem.**WordNetLemmatizer**
  - nltk.tokenize.**word_tokenize**
- numpy
- pandas
- sklearn
  - sklearn.feature_extraction.text.**TfidfVectorizer**
  - sklearn.linear_model.**LogisticRegression**
  - sklearn.metrics.**f1_score**
  - sklearn.**model_selection**
  - sklearn.tree.**DecisionTreeClassifier**
- tqdm.notebook.**tqdm**

## Общий вывод
**Цели проекта выполнены. В ходе выполнения работы проделаны следующие шаги:**
- Загружены и проверены соответствия данных в датафреймах;
- Индексы установлены по порядку возрастания без пропусков;
- Проверено наличие дубликатов и пропусков (отсутствуют);
- Проведена лемматизация текста, удалены неинформативные символы;
- Данные разбиты на тренировочную и обучающую выборки;
- Тексты приведены к векторному представлению;
- Обучены модели (`LinearRegression`, `DecisionTree`)
- Найдена лучшая модель:
    - Лучшей моделью является **LinearRegression** с параметрами `C=6`, `penalty='l1'`. Метрика модели соответсвует критериям заказчика (*значение на тестовой выборке F1 не меньше 0.75*) и дает следующие результаты:
        - Метрика **F1** на тренировочной выборке: **0.77**
        - Метрика **F1** на тестовой выбборке: **0.78**  
